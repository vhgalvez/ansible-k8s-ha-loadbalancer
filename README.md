# üß∞ HAProxy + Keepalived Deployment (Ansible)

Este repositorio despliega un balanceador de carga con alta disponibilidad usando **HAProxy** y **Keepalived** para cl√∫steres Kubernetes (K3s o Kubernetes tradicionales). Proporciona balanceo de tr√°fico en las capas TCP/HTTP y maneja m√∫ltiples VIPs para separar tr√°fico del API y del Ingress.

---

## üß± Visi√≥n General: ¬øQu√© est√°s construyendo?

Est√°s construyendo un entorno Kubernetes de alta disponibilidad sobre m√°quinas virtuales KVM en un servidor f√≠sico HP ProLiant, utilizando K3s, HAProxy + Keepalived, Traefik como Ingress interno, y almacenamiento distribuido con Longhorn + NFS, todo asegurado mediante VPN WireGuard y nftables.

---

## üåê Arquitectura de Red y Accesos Externos

```plaintext
[Usuarios P√∫blicos]
       ‚îÇ
       ‚ñº
+-------------------+
| Cloudflare CDN    | ‚óÑ‚îÄ‚îÄ Proxy + HTTPS + WAF
| (example.com)     |
+-------------------+
       ‚îÇ
       ‚ñº
+----------------------------+
| VPS con IP p√∫blica         |
| WireGuard Gateway          |
| T√∫nel: 10.17.0.1           |
+----------------------------+
       ‚îÇ
       ‚ñº
+-----------------------------+
| WireGuard Server LAN       |
| NAT + VPN (192.168.0.20)   |
+-----------------------------+
       ‚îÇ
       ‚ñº
Tr√°fico Interno Redirigido Seg√∫n Tipo
```

### üéØ Separaci√≥n de Tr√°fico en Producci√≥n

| Tipo de Tr√°fico       | VIP Asignada | Funci√≥n                                                |
| --------------------- | ------------ | ------------------------------------------------------ |
| Kubernetes API (6443) | 10.17.5.10   | Requiere estabilidad para kubectl, etcd, control-plane |
| Ingress HTTP/HTTPS    | 10.17.5.30   | Redirige tr√°fico a servicios internos v√≠a Traefik      |

Estas IPs virtuales (VIP) son gestionadas por HAProxy + Keepalived y conmutan entre nodos autom√°ticamente.

### üß† Balanceadores HA

| Nodo          | IP         | Funci√≥n                |
| ------------- | ---------- | ---------------------- |
| k8s-api-lb    | 192.168.0.30 | Nodo principal de VIPs con br0 puente|
| loadbalancer1 | 10.17.3.12 | Respaldo HAProxy       |
| loadbalancer2 | 10.17.3.13 | Respaldo HAProxy       |

Los tres tienen HAProxy + Keepalived instalados.

Las VIPs 10.17.5.10 (API) y 10.17.5.30 (Ingress) son flotantes. Solo un nodo las mantiene activas al mismo tiempo (por prioridad).

---

## ‚ò∏Ô∏è Cl√∫ster Kubernetes (K3s HA)

| Hostname | IP         | Rol                  |
| -------- | ---------- | -------------------- |
| master1  | 10.17.4.21 | etcd + API           |
| master2  | 10.17.4.22 | etcd                 |
| master3  | 10.17.4.23 | etcd                 |
| worker1  | 10.17.4.24 | Nodo de aplicaciones |
| worker2  | 10.17.4.25 | Nodo de aplicaciones |
| worker3  | 10.17.4.26 | Nodo de aplicaciones |

Todos los nodos usan Flatcar Container Linux. Cl√∫ster K3s en modo etcd HA.

Se instala con `--tls-san 10.17.5.10` para que `kubectl` acceda v√≠a la VIP.

---

## üö™ Ingress Controller (Traefik)

| Tipo    | Despliegue                       |
| ------- | -------------------------------- |
| Traefik | Deployment interno en Kubernetes |

El acceso es a trav√©s de la VIP `10.17.5.30` gestionada por HAProxy. Traefik se comunica con los pods v√≠a ClusterIP. No se expone directamente.

---

## üíæ Almacenamiento Persistente

| Nodo     | IP         | Rol            |
| -------- | ---------- | -------------- |
| storage1 | 10.17.4.27 | NFS + Longhorn |

**Longhorn (RWO):**

- Microservicios
- Prometheus
- Grafana
- ELK

**NFS (RWX):**

- PostgreSQL ‚Üí `/srv/nfs/postgresql`
- Datos compartidos ‚Üí `/srv/nfs/shared`

---

## üîê Seguridad

| Componente    | Detalles                                |
| ------------- | --------------------------------------- |
| WireGuard     | Acceso remoto seguro desde el VPS       |
| nftables      | Firewall estricto en el servidor f√≠sico |
| Cloudflare    | HTTPS, WAF, Protecci√≥n contra DDoS      |
| Autenticaci√≥n | basicAuth en dashboards internos        |
| DNS/NTP       | infra-cluster (`10.17.3.11`)            |

---

## üß† Automatizaci√≥n y CI/CD

| Herramienta      | Funci√≥n                                |
| ---------------- | -------------------------------------- |
| Terraform        | Provisi√≥n de VMs y redes               |
| Ansible          | Instalaci√≥n y configuraci√≥n (100% IaC) |
| Jenkins + ArgoCD | CI/CD interno                          |

---

## üñ• Tabla de M√°quinas

| Hostname      | IP         | Funci√≥n                     |
| ------------- | ---------- | --------------------------- |
| master1       | 10.17.4.21 | K3s Master + etcd           |
| master2       | 10.17.4.22 | K3s Master + etcd           |
| master3       | 10.17.4.23 | K3s Master + etcd           |
| worker1       | 10.17.4.24 | Nodo de aplicaciones        |
| worker2       | 10.17.4.25 | Nodo de aplicaciones        |
| worker3       | 10.17.4.26 | Nodo de aplicaciones        |
| storage1      | 10.17.4.27 | Longhorn + NFS              |
| k8s-api-lb    | 1192.168.0.30 | HAProxy + Keepalived (VIPs) |
| loadbalancer1 | 10.17.3.12 | HAProxy (respaldo)          |
| loadbalancer2 | 10.17.3.13 | HAProxy (respaldo)          |
| postgresql1   | 10.17.3.14 | PostgreSQL centralizado     |
| infra-cluster | 10.17.3.11 | CoreDNS + Chrony            |

---

## ‚úÖ Ventajas de esta Arquitectura

- Alta disponibilidad real con m√∫ltiples VIPs separadas.
- Ingress controlado internamente con Traefik.
- Seguridad robusta por VPN, nftables y HTTPS.
- Automatizaci√≥n total (Terraform + Ansible).
- Almacenamiento distribuido y tolerante a fallos.
- Modularidad para crecer sin redise√±ar.

sudo ansible-playbook -i inventory/hosts.ini ansible/playbooks/install_haproxy_keepalived.yml


sudo ansible-playbook -i inventory/hosts.ini ansible/playbooks/uninstall_haproxy_keepalived.yml


# üß∞ Documentaci√≥n: Bootstrap de Cl√∫ster K3s con HAProxy + Keepalived + VIPs

## üìÑ Objetivo

Permitir que el nodo `master1` pueda iniciar el cl√∫ster K3s sin depender previamente de que HAProxy o Keepalived est√©n activos y funcionales. Esto resuelve el cl√°sico problema de dependencia c√≠clica ("el huevo o la gallina") al usar una VIP (IP virtual) como punto de entrada al cl√∫ster.

---

## üèõÔ∏è Arquitectura

* **VIP del API Server**: `10.17.5.10`
* **VIP del Ingress**: `10.17.5.30`
* **Masters**:

  * `10.17.4.21` (bootstrap)
  * `10.17.4.22`
  * `10.17.4.23`
* **Workers**:

  * `10.17.4.24`, `10.17.4.25`, `10.17.4.26`, `10.17.4.27`
* **Load Balancers**:

  * `10.17.3.12`, `10.17.3.13`, `192.168.0.30`

---


k8s-api-lb 192.168.0.30 se crea un adaptador de puente `br0` para que los nodos puedan comunicarse entre s√≠ y con el mundo exterior.

## üîÑ Orden de inicio esperado

1. El nodo `master1` se inicializa con su IP real (`10.17.4.21`).
2. Se levanta el `k3s-server` y el `etcd` en `master1`.
3. Los otros masters se unen usando `https://10.17.4.21:6443` (no la VIP).
4. Una vez el cl√∫ster est√° operativo:

   * Se configura la VIP (`10.17.5.10`) con Keepalived.
   * Se habilita HAProxy en los nodos `haproxy_keepalived`.
5. HAProxy redirige el tr√°fico de `10.17.5.10:6443` hacia los masters disponibles.
6. El `kubeconfig` puede comenzar a usar la VIP como endpoint oficial.

---

## ‚úÖ Configuraci√≥n correcta para romper el ciclo

### 1. **`master1` usa su IP real para bootstrap**

* El script de Ansible no apunta a la VIP (`10.17.5.10`) para levantar el nodo inicial.
* Esto permite iniciar el API Server antes que HAProxy.

### 2. **HAProxy permite `bind` en IPs no locales**

```yaml
- name: Habilitar net.ipv4.ip_nonlocal_bind
  ansible.posix.sysctl:
    name: net.ipv4.ip_nonlocal_bind
    value: "1"
    sysctl_file: /etc/sysctl.d/99-haproxy-nonlocal-bind.conf
    reload: yes
    state: present
```

Esto evita errores de HAProxy como `Cannot bind to VIP`, ya que permite iniciar el proceso sin que la IP est√© asignada localmente a la interfaz.

### 3. **Keepalived no requiere HAProxy para iniciar**

```ini
# override.conf
[Unit]
After=haproxy.service
# NO incluye Requires=haproxy.service
```

Esto asegura que Keepalived pueda arrancar independientemente de HAProxy. La relaci√≥n es suave, no bloqueante.

### 4. **VIP solo se usa despu√©s de la estabilizaci√≥n**

* El uso de la VIP para el `kubeconfig` solo se hace despu√©s de validar que el balanceador HAProxy est√© activo.

### 5. **Configuraci√≥n de HAProxy**

El `haproxy.cfg` est√° correctamente estructurado para enrutar tr√°fico TCP en el puerto 6443 hacia los masters:

```haproxy
frontend kubernetes_api
    bind 10.17.5.10:6443
    mode tcp
    option tcplog
    default_backend kubernetes_masters

backend kubernetes_masters
    mode tcp
    balance roundrobin
    option tcp-check
    tcp-check connect port 6443
    default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions
    server master-1 10.17.4.21:6443 check
    server master-2 10.17.4.22:6443 check
    server master-3 10.17.4.23:6443 check
```

---

## üîß Validaciones adicionales

* Comando para verificar si HAProxy permite bind:

```bash
sysctl net.ipv4.ip_nonlocal_bind
```

* Verificar configuraci√≥n de HAProxy:

```bash
haproxy -c -f /etc/haproxy/haproxy.cfg
```

* Verificar si est√° corriendo:

```bash
sudo systemctl status haproxy
```

---

## üß™ Estado de los Balanceadores tras el Playbook `install_haproxy_keepalived.yml`

Este es el estado esperado de los nodos balanceadores una vez finaliza la instalaci√≥n autom√°tica con Ansible. Todos los nodos tienen HAProxy + Keepalived configurados, y las VIPs se asignan autom√°ticamente por prioridad.

| Hostname        | IP           | Rol                                 | Keepalived         | HAProxy             | VIPs Activas                      |
|-----------------|--------------|--------------------------------------|--------------------|---------------------|------------------------------------|
| `k8s-api-lb`    | `192.168.0.30` | Nodo principal de VIPs (`priority=100`) | ‚úÖ Activo (MASTER)  | ‚úÖ Activo y corriendo | ‚úÖ `10.17.5.10` y `10.17.5.30`      |
| `loadbalancer1` | `10.17.3.12` | Respaldo 1 (`priority=120`)         | ‚úÖ Activo (BACKUP)  | ‚úÖ Activo (en espera) | ‚ùå (asumir√° VIPs si el principal cae) |
| `loadbalancer2` | `10.17.3.13` | Respaldo 2 (`priority=110`)         | ‚úÖ Activo (BACKUP)  | ‚úÖ Activo (en espera) | ‚ùå (asumir√° VIPs si los anteriores caen) |

---

### ‚öôÔ∏è Detalles t√©cnicos

- Todos los nodos tienen `HAProxy` habilitado y en ejecuci√≥n (`enabled + running`).
- Todos usan `ip_nonlocal_bind=1` para permitir el arranque sin poseer la VIP localmente.
- Keepalived gestiona la flotaci√≥n de las siguientes IPs virtuales:
  - `10.17.5.10` ‚Üí Kubernetes API (`6443`)
  - `10.17.5.30` ‚Üí Ingress HTTP/HTTPS (`80` y `443`)
- El nodo que obtiene las VIPs es determinado por el archivo `host_vars/<ip>.yml` con sus prioridades:
  - `keepalived_priority_api`
  - `keepalived_priority_ingress`
- Si el nodo principal falla, el siguiente en prioridad **asume autom√°ticamente las VIPs** y el tr√°fico contin√∫a sin interrupciones.

---


## üéØ Conclusi√≥n

Con esta configuraci√≥n:

* El nodo `master1` puede iniciar el cl√∫ster sin la VIP.
* Los nodos balanceadores y Keepalived pueden arrancar sin romper dependencias.
* HAProxy puede arrancar incluso si no posee la VIP.

üëç Est√°s aplicando correctamente un patr√≥n de alta disponibilidad tolerante a fallos y circularidades de dependencia.



ansible-galaxy collection install community.general

üß∞ Resumen del Proyecto: HAProxy + Keepalived para K3s HA
Este proyecto implementa una soluci√≥n de balanceo de carga altamente disponible para el acceso al cl√∫ster Kubernetes mediante HAProxy y Keepalived, gestionando m√∫ltiples VIPs (IP Virtuales) para separar tr√°fico cr√≠tico del API y del Ingress HTTP/HTTPS.

üéØ Objetivo
Garantizar:

Acceso ininterrumpido al API de Kubernetes (puerto 6443).

Disponibilidad continua para tr√°fico HTTP/HTTPS hacia los servicios internos (Ingress).

Failover autom√°tico de las IPs virtuales entre m√∫ltiples nodos balanceadores.

üîß Componentes Clave
Componente	Descripci√≥n
HAProxy	Balanceador de carga TCP/HTTP para API y tr√°fico web
Keepalived	Gestor de alta disponibilidad mediante VRRP para mover VIPs entre nodos
VIPs	IPs flotantes que garantizan un √∫nico punto de entrada para el tr√°fico
Ansible	Automatizaci√≥n completa del despliegue y configuraci√≥n
K3s	Cl√∫ster Kubernetes ligero y altamente disponible

üåê Arquitectura General de Red
bash
Copiar
Editar
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ        Clientes externos    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                           ‚îÇ Cloudflare‚îÇ
                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                       VPN / NAT / WireGuard
                                 ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Load Balancer Principal‚îÇ  <- VIPs: 10.17.5.10 / 10.17.5.30
                    ‚îÇ   (HAProxy + Keepalived)‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ                                   ‚îÇ
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ  K3s Master #1  ‚îÇ               ‚îÇ  K3s Master #2-3    ‚îÇ
     ‚îÇ API + etcd      ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ API + etcd           ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

              ‚îÇ Ingress tr√°fico HTTP/HTTPS via Traefik
              ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  Workers   ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
üì¶ VIPs y Tr√°fico
Tipo de Tr√°fico	Puerto(s)	VIP	Destino final
API de Kubernetes	6443	10.17.5.10	Nodos master de K3s (HA)
Servicios Ingress	80 / 443	10.17.5.30	Nodos worker v√≠a Traefik (interno)

Las VIPs son asignadas din√°micamente al nodo con mayor prioridad activa.

Si un nodo falla, Keepalived transfiere la VIP al siguiente disponible.

üõ†Ô∏è Mecanismo de Alta Disponibilidad
HAProxy:

Act√∫a como proxy TCP para 6443 y como proxy HTTP para 80/443.

Verifica salud de los nodos K3s y trabajadores.

Permite configuraci√≥n nonlocal_bind para bindear IPs no locales.

Keepalived:

Ejecuta VRRP y scripts de tracking (estado de HAProxy).

Usa prioridad para determinar nodo MASTER de las VIPs.

Ejecuta vip_master.sh, vip_backup.sh, vip_fault.sh seg√∫n evento.

Ansible:

Automatiza instalaci√≥n en nodos HA.

Configura todos los archivos .cfg, .service, .conf necesarios.

Detecta Flatcar y aplica configuraciones especiales si es necesario.

üìë Flujo de Implementaci√≥n con Ansible
Detecta distribuci√≥n (Flatcar o no).

Instala HAProxy, Keepalived y dependencias.

Configura sysctl para permitir nonlocal_bind.

Aplica configuraciones plantilladas (haproxy.cfg.j2, keepalived.conf.j2).

Configura override de systemd para evitar dependencias circulares.

Reinicia servicios y valida salud.

‚úÖ Ventajas Clave
Alta disponibilidad real (failover autom√°tico).

Separaci√≥n de tr√°fico cr√≠tico.

Escalabilidad horizontal simple.

Configuraci√≥n 100% automatizada y auditable (IaC).

Seguridad de acceso por VPN y Cloudflare (si aplica).
---
ansible-k8s-ha-loadbalancer/
‚îú‚îÄ‚îÄ ansible.cfg
‚îú‚îÄ‚îÄ inventory/
‚îÇ   ‚îî‚îÄ‚îÄ hosts.ini
‚îú‚îÄ‚îÄ host_vars/
‚îÇ   ‚îú‚îÄ‚îÄ 10.17.3.12.yml        # loadbalancer1
‚îÇ   ‚îú‚îÄ‚îÄ 10.17.3.13.yml        # loadbalancer2
‚îÇ   ‚îî‚îÄ‚îÄ 192.168.0.30.yml        # k8s-api-lb (nodo principal)
‚îú‚îÄ‚îÄ playbooks/
‚îÇ   ‚îî‚îÄ‚îÄ install_haproxy_keepalived.yml
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îú‚îÄ‚îÄ haproxy/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ haproxy.cfg.j2
‚îÇ   ‚îî‚îÄ‚îÄ keepalived/
‚îÇ       ‚îî‚îÄ‚îÄ keepalived.conf.j2
‚îú‚îÄ‚îÄ Makefile
‚îî‚îÄ‚îÄ README.md
---




üñ•Ô∏è Tabla de M√°quinas y Servicios
Hostname	IP	Rol	Servicio	Estado Esperado	Comentario
k8s-api-lb	192.168.0.30	Nodo principal de balanceo	haproxy	üü¢ Activo	Nodo que deber√≠a mantener las VIPs activas (por prioridad m√°s baja)
keepalived	üü¢ Activo (MASTER)	Controla VIPs 10.17.5.10 (API) y 10.17.5.30 (Ingress)
loadbalancer1	10.17.3.12	Nodo de respaldo 1 de balanceo	haproxy	üü¢ Activo	Nodo backup, asume VIPs si k8s-api-lb cae
keepalived	üü¢ Activo (BACKUP)	Se convierte en MASTER si el nodo principal falla
loadbalancer2	10.17.3.13	Nodo de respaldo 2 de balanceo	haproxy	üü¢ Activo	Segundo backup, entra si ambos anteriores fallan
keepalived	üü¢ Activo (BACKUP)	Estado pasivo, listo para asumir en caso de emergencia
master1	10.17.4.21	Kubernetes API + etcd + bootstrap	k3s server	üü¢ Activo	Primer nodo que inicia el cluster sin necesidad de VIP
master2	10.17.4.22	Kubernetes API + etcd	k3s server	üü¢ Activo	Se une al cl√∫ster v√≠a IP real o API VIP
master3	10.17.4.23	Kubernetes API + etcd	k3s server	üü¢ Activo	Parte del quorum de etcd
worker1	10.17.4.24	Nodo de aplicaci√≥n	k3s agent	üü¢ Activo	Recibe tr√°fico HTTP/HTTPS v√≠a Traefik + VIP Ingress
worker2	10.17.4.25	Nodo de aplicaci√≥n	k3s agent	üü¢ Activo	Balanceado por Traefik
worker3	10.17.4.26	Nodo de aplicaci√≥n	k3s agent	üü¢ Activo	Balanceado por Traefik
storage1	10.17.4.27	NFS + Longhorn	nfs-server	üü¢ Activo	Montado como RWX (PostgreSQL, compartido) y RWO (Longhorn)
infra-cluster	10.17.3.11	DNS (CoreDNS), NTP (Chrony)	dns, ntp	üü¢ Activo	Servidor de infraestructura para sincron√≠a y resoluci√≥n interna
postgresql1	10.17.3.14	Base de datos centralizada	postgresql	üü¢ Activo	Puede estar montado en NFS compartido

üéØ Comportamiento de Failover de Keepalived
üß† VIP 10.17.5.10 (API Server)
Asignada por defecto al nodo k8s-api-lb

Si este cae:

loadbalancer1 detecta la ca√≠da y asume la IP VIP

Si tambi√©n cae, loadbalancer2 asume la IP

‚û°Ô∏è El acceso al API (puerto 6443) sigue funcionando sin interrupciones para kubectl, etcd, y kubelet.

üåê VIP 10.17.5.30 (Ingress HTTP/HTTPS)
Tambi√©n manejada por k8s-api-lb

Redirige tr√°fico HTTP/HTTPS (puertos 80/443) hacia los pods (Traefik interno)

Failover autom√°tico entre los tres balanceadores seg√∫n prioridad

‚û°Ô∏è El tr√°fico web externo es reenviado correctamente a trav√©s del Ingress aunque un nodo de balanceo falle.

üìä Resumen de Estados Esperados

| Nodo            | Servicio    | Estado         | Observaciones                              |
|-----------------|-------------|----------------|-------------------------------------------|
| k8s-api-lb      | haproxy     | ‚úÖ corriendo   | Posee ambas VIPs (por prioridad)          |
|                 | keepalived  | ‚úÖ corriendo   | Estado MASTER                             |
| loadbalancer1   | haproxy     | ‚úÖ corriendo   | Espera en BACKUP                          |
|                 | keepalived  | ‚úÖ corriendo   | BACKUP con menor prioridad                |
| loadbalancer2   | haproxy     | ‚úÖ corriendo   | Espera en BACKUP                          |
|                 | keepalived  | ‚úÖ corriendo   | BACKUP                                    |

## üì¶ Importante sobre HAProxy

- Requiere `net.ipv4.ip_nonlocal_bind = 1` para aceptar conexiones en IPs VIP que no est√©n asignadas localmente.
- Se arranca incluso si la VIP no est√° disponible a√∫n (por dise√±o de HA).
- Las configuraciones est√°n correctamente desacopladas gracias al override systemd y `After=haproxy.service`.

## ‚úÖ Conclusiones

- Tu dise√±o es resiliente, modular y de alta disponibilidad real.
- El cl√∫ster no depende de las VIPs para arrancar, lo cual rompe el ciclo ‚Äúhuevo-gallina‚Äù.
- En caso de falla de cualquier balanceador, los otros asumen sin intervenci√≥n humana.
- La infraestructura est√° lista para producci√≥n y escalamiento.

# üì¶ Instalaci√≥n de HAProxy y Keepalived

```bash
sudo ansible-playbook playbooks/setup_haproxy_keepalived_full.yml -i inventory/hosts.ini+
```
